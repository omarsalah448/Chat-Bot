{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m3VGaKCwdnyk",
    "outputId": "61853652-6d7f-4f9a-b2bc-0790f37aac02"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "import random\n",
    "import pandas as pd\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tSrrsYMqeO2c",
    "outputId": "83739d43-cc20-480b-9db0-1590cf4aa6a7"
   },
   "outputs": [],
   "source": [
    "with open('intents.json') as file:\n",
    "    myfile = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "M4TPAnubeO4T"
   },
   "outputs": [],
   "source": [
    "s = LancasterStemmer()\n",
    "\n",
    "botrespose = []\n",
    "botTrain = []\n",
    "mytags = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "JSibYBQzeO7h"
   },
   "outputs": [],
   "source": [
    "for intent in myfile['intents']:\n",
    "    \n",
    "    for pattern in intent['patterns']:\n",
    "        myWords = pattern.lower()\n",
    "        myWords = word_tokenize(myWords)\n",
    "        myWords = [s.stem(w) for w in myWords]\n",
    "        myWords = \" \".join(myWords)\n",
    "        botTrain.append(myWords)\n",
    "        \n",
    "        mytags.append(intent['tag'])\n",
    "\n",
    "    botrespose.append(intent['responses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(tag):\n",
    "    words = ['greetings', 'games', 'favoriteHobby', 'friends', 'family', 'favoriteBook',\n",
    "             'sad', 'school', 'secret', 'love', 'secret', 'speak', 'creation', 'goodbye']\n",
    "    \n",
    "    try:\n",
    "        return words.index(tag)\n",
    "    except ValueError:\n",
    "        return tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "ZLW67ElzePAL"
   },
   "outputs": [],
   "source": [
    "mytags = pd.DataFrame(mytags)\n",
    "mytags[0] = mytags[0].apply(transform)\n",
    "mytags = mytags[0].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "26980VNyePB_"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "result = cv.fit_transform(botTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k2zb7cQgePFC",
    "outputId": "ed8cffab-142f-4f05-a1bd-ef2b90d9d198"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticModel = LogisticRegression()\n",
    "logisticModel.fit(result, mytags)\n",
    "print(logisticModel.score(result, mytags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "id": "mmq6gyZWePHy",
    "outputId": "5e069a4c-23be-4253-dc15-7e221197223a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please type here........: nye\n",
      "hi\n",
      "please type here........: bye\n",
      "It was nice talking to you, hope you come back again\n"
     ]
    }
   ],
   "source": [
    "quit_word = ['quit', 'exit', 'stop', 'bye']\n",
    "while True:\n",
    "    new = input(\"please type here........: \")\n",
    "    new = new.lower()\n",
    "    if new in quit_word:\n",
    "        print('It was nice talking to you, hope you come back again')\n",
    "        break\n",
    "    new = word_tokenize(new)\n",
    "    myWords = [s.stem(n) for n in new]\n",
    "    myWords = \" \".join(myWords)\n",
    "    txt = [myWords]\n",
    "    new_cv = cv.transform(txt)\n",
    "\n",
    "    out_put = logisticModel.predict(new_cv)\n",
    "\n",
    "    out = random.choice(botrespose[int(out_put[0])])\n",
    "    print(out)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled56.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
